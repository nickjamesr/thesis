\chapter{Tomography of Hamiltonians}
\label{ch:Hamiltomo}

\section{Introduction}
\label{sec:HTIntro}
In this chapter I discuss a procedure that I developed to determine the
(time constant) Hamiltonian governing the evolution of a system of
non-interacting Bosons in a discrete space. The process requires measurements of
single particle states and two particle correlations, and the number of
measurements scales polynomially with the number of system modes. It relies on
making measurements of the time evolution operator for multiple (minimum two,
preferably at least three) time increments.

In order to measure the time
evolution operator, I rely the method described in~\cite{sst} for efficiently
determining the unitary describing a linear optical circuit, or a similar
method. In section~\ref{sec:SST} I present a review of this method, and how it
is adapted to work in practice. Section~\ref{sec:Hamiltomo} describes in detail
the process for determining the Hamiltonian from multiple measurements of the
time evolution operator. Finally, section~\ref{sec:HTExperiment} contains
results of an experimental application of the process to a linear optical
quantum walk.

\section{Tomography of a unitary}
\label{sec:SST}
This section is a review of the method in~\cite{sst} (SST) for efficiently
determining the unitary description of a linear optical circuit. It is not my
own work, but it is important background for the results that follow.

Any linear optical device on \(m\) modes can be described in its entirety by an
\(m \by m\) unitary matrix, \(\mat{U}\). Since photons do not interact, this
matrix is sufficient to decsribe the action of the device on any number of
photons, even if the calculation of the transfer elements does not scale
polynomially with the number of photons, \(p\). This means that a full
description of the device can be expressed in only \(m^{2}\) real
parameters\footnote{An \(m \by m\) unitary matrix is normally written in terms
of \(m^{2}\) complex numbers (therefore \(2m^{2}\) real parameters) but the
constraints of unitary remove half of these.}. In SST, Laing and O'Brien
present a method for determining all of these parameters experimentally, with
measurements of single photons (or equivalently coherent states) and photon
pairs. No higher photon numbers are required.

Each element in the unitary matrix is a complex number, and can therefore be
expressed as an amplitude and a phase. The scheme begins by examining the
amplitudes. In the absence of loss, if we inject coherent light with power \(P\)
into mode \(j\), then the power measured in output mode \(i\) is \(P_{ij} =
P \abs{u_{ij}}^{2}\) (where \(u_{ij}\) is the \(i,j^{\text{th}}\) element of
\(\mat{U}\)). By taking power measurements for each of the \(m^{2}\)
input/output pairs, we could deduce the amplitudes of all the matrix elements.

The presence of loss complicates matters. Suppose the efficiency of inserting a
photon in mode \(j\) is \(\eta_{j}^{\text{(in)}}\) and the efficiency of the
detector on mode \(i\) is \(\eta_{i}^{\text{(out)}}\), then the expression for
the output power becomes \(P_{ij} = P \eta_{j}^{\text{(in)}} \abs{u_{ij}}^{2}
\eta_{i}^{\text{(out)}}\), and we are unable to separate the amplitudes from the
efficiencies (or equivalently losses). At this point, the SST procedure
constructs ratios of powers in which the losses cancel:
\begin{equation}
  \label{eq:ratios}
  R_{ijkl} = \frac{P_{ik} P_{jl}}{P_{il} P_{jk}} = \frac{\abs{u_{ik}}^{2}
  \abs{u_{jl}}^{2}}{\abs{u_{il}}^{2} \abs{u_{jk}}^{2}}
\end{equation}
These become useful later in discussion of the phases, but for determining the
amplitudes there is an easier approach, making use of the Sinkhorn-Knopp
algorithm~\cite{sinkhorn-knopp}. The algorithm takes the raw matrix of powers,
\(\mat{P}\) and iteratively pre- and post- multiplying by real diagonal matrices
such that the rows and columns are normalised to 1. Sinkhorn's
theorem~\cite{sinkhorn} implies that this process will converge on the matrix
of absolute squares of elements of \(\mat{U}\). By keeping track of the diagonal
matrices, estimates of the losses can also be extracted. This procedure has been
developed in the context of linear optics by Jacques Carolan and used
extensively in the lab for reconstructing unitaries.

In order to determine the phases of the elements of \(\mat{U}\), we must either
employ interferometric techniques (as in \cite{sst-ralph}) or look at quantum
interference between pairs of photons, as in the SST protocol. Consider
injecting two photons in modes \(k\) and \(l\) with a variable time delay,
\(\delta\) and measuring coincident detections in modes \(i\) and \(j\) as a
function of \(\delta\). The result is a generalisation of the Hong Ou Mandel
(HOM) dip described in~\cite{hom} and will be a dip (or antidip) with visibility
\(V_{ijkl}\). The visibility is a function of the \emph{quantum}
coincidence rate, \(Q_{ijkl}\) (where \(\delta=0\)) and the \emph{classical}
coincidence rate, \(C_{ijkl}\) (where \(\delta\) is large enough to neglect
interference between the photons), defined as
\begin{equation}
  V_{ijkl} = \frac{C_{ijkl} - Q_{ijkl}}{C_{ijkl}}
\end{equation}
It can take values between -1 (perfect antidip, constructive quantum
interference) and +1 (perfect dip, destructive quantum interference). Since the
numerator and the denominator are affected equally by losses at inputs and
outputs, this quantity is independent of losses. We can express it in terms of
other loss-independent quantities (the ratios described in
equation~\ref{eq:ratios}) and the relative phases on elements of the unitary:
\begin{equation}
  V_{ijkl} = -\frac{2 \sqrt{R_{ijkl}} \cos \theta_{ijkl}}{1+R_{ijkl}}
\end{equation}
where \(\theta_{ijkl} = \phi_{ik} + \phi_{jl} - \phi_{il} - \phi_{jk}\) and
\(u_{ij} = \abs{u_{ij}}e^{i\phi_{ij}}\).

Thus we can deduce, from loss independent measurements, a set of relationships
between the phases of elements of the unitary. In order to make progress, we
must choose a row and a column as \emph{reference elements}, assumed to be real;
all other phases can now be completely specified relative to these. This freedom
to choose a reference reflects an invariance in the experiment. Since we prepare
and measure in the computational basis, we can pre- or post- multiply by a
diagonal matrix of phases with no effect on any observable quantities. We
therefore couldn't expect to specify the phases any more precisely than this.

It will become evident in later sections that this does not imply that all
choices of references are equally valid. Consider using row \(\alpha\) and
column \(\beta\) to deduce the phase of an element \(u_{jl}\) where \(j \neq
\alpha\) and \(l \neq \beta\):
\begin{align}
  && \cos{\phi_{jl}} &= - V_{\alpha j \beta l} \frac{1 + R_{\alpha j \beta l}}
    {2 \sqrt{R_{\alpha j \beta l}}} && \\
  \text{where} && R_{\alpha j \beta l} &= \frac{P_{\alpha \beta}
    P_{jl}}{P_{\alpha l} P_{j \beta}} &&
\end{align}
This method works fine unless one of the powers \(P_{\alpha \beta},
P_{\alpha l}, P_{j \beta}\) is equal to zero, in which case the phase is
undefined (if \(P_{jl}=0\) we do not need to know its phase). It is therefore
important to select references in such a way as to minimize the number of zero
elements.

\section{Tomography of a Hamiltonian}
\label{sec:Hamiltomo}
Now that we know we can determine the unitary description of a fixed quantum
process in linear optics, I apply this result to a general system of
non-interacting bosons evolving under a time-constant Hamiltonian in a discrete,
finite space. In particular, using measurements of the unitary time evolution
operator for the system at multiple time increments, we can deduce the
Hamiltonian underlying the evolution.

In practice, the experimental requirements are:
\begin{itemize}
  \item Preparation of arbitrary 1- and 2-particle states in the computational
  basis
  \item Precise control over the evolution time
  \item Arbitrary measurement of mode occupation and pairwise correlations
  between occupations (again, in the computational basis)
\end{itemize}

Recall that in a discrete, finite space of \(m\) orthogonal modes, the
Hamiltonian can be expressed exactly as an \(m \by m\) Hermitian matrix, and the
time evolution operator is an \(m \by m\) unitary matrix. If the Hamiltonian
\(\mat{H}\) is constant in time, the relationship between the time evolution
operator, \(\mat{U}\) and the Hamiltonian is:
\begin{equation}
  \label{eq:exponential}
  \mat{U} \of{t} = e^{-i \mat{H} t}
\end{equation}

Now consider taking the time derivative of this expression:
\begin{equation}
  \mat{U}^{\prime} \of{t} = -i \mat{H} e^{-i \mat{H} t} = -i \mat{H} \mat{U}
  \of{t}
\end{equation}
If we could measure \(\mat{U}^{\prime}\) directly, we would be done at this
point and the Hamiltonian would be revealed by:
\begin{equation}
  \mat{H} = i \mat{U}^{\prime} \of{t} \mat{U}^{\dagger} \of{t}
\end{equation}
for any time \(t\).

In order to avoid reliance on direct measurements of \(\mat{U}^{\prime}\), we
can instead discretise the derivative, and take multiple measurements of
\(\mat{U}\) in place of a single measurement of \(\mat{U}^{\prime}\). Here I
present the commonly-used 3-point time derivative, and derive the following
expression for \(\mat{H}\):
\begin{equation}
  \label{eq:hamiltomo}
  \mat{H} = \frac{i}{2 \dt} \left[ \mat{U} \of{t+\dt} - \mat{U} \of{t-\dt}
  \right] \mat{U}^{\dagger} \of{t}
\end{equation}
Note that this is not the only way to recover the Hamiltonian from measurements
of \(\mat{U}\). Alternatives, such as the matrix logarithm and series expansions
are discussed briefly in section~\ref{sec:Alternatives}. The rest of this
section concerns the factors involved in choosing the step size, \(\dt\).

\begin{figure}[h]
  \centering
  \includegraphics{figures/timestep}
  \caption[Error in Hamiltonian reconstruction as a function of step size]
  {Error in Hamiltonian reconstruction as a function of step size, under varying
  noise from experimental error. All simulations are for a \(9 \by 9\)
  tridiagonal Hamiltonian, with noise applied directly to the unitary.
  In the absence of noise, the error in the
  reconstruction decreases as \(\dt^{2}\), since we are using the 3-point
  numerical derivative. In the presence of noise, there is an optimum point. For
  step sizes below this, the difference between the two unitaries being
  subtracted is swamped by the noise and the fidelity starts to decrease again.
  Shaded regions show \(1 \sigma\) variations over Monte-Carlo simulations of
  noise in the unitary.}
  \label{fig:stepsize}
\end{figure}

Like any discrete calculus method, the discretisation length (step size) affects
the accuracy of the method greatly. Figure~\ref{fig:stepsize} illustrates the
effect of varying the step size in a simulated experimental context.
\todo{Explain the noise mechanism - essentially dialling error \(\varepsilon\)
on each of the phases in an integrated Reck scheme}.

\section{Experimental implementation}
\label{sec:HTExperiment}
In photonics we have excellent sources and detectors \todo{citations}, so the
requirements of
arbitrary preparation and measurement in the computational basis are easy to
meet. The requirement that we have control over the evolution time is a more
difficult. In free space we could move the detectors closer to or further from
the source, but the Hamiltonian describing photons propagating in free space is
diagonal so the experiment would not be very interesting. Free space components
with more interesting Hamiltonians such as waveplates tend to be fixed, so we
have no control whatsoever over the evolution time!

A solution is presented in integrated optics. Consider a continuously coupled
quantum walk, where each waveguide is coupled to its nearest neighbour: the
effective evolution time is proportional to the optical path length of the
coupling region. We cannot easily vary the physical length of the coupling
region, but by varying the wavelength of the light, we can change the optical
length. We use this technique on a 21 mode continuously coupled quantum walk to
obtain the results in this section. Note that the setup and wavelength shifting
of the source, and most of the data acquisition was was done by Jacques Carolan.
I did the remaining data acquisition and all the data analysis.

The construction of the quantum walk allows coupling between nearest-neighbour
waveguides with negligible longer range couplings. The chip that we use is
designed to have uniform couplings. We therefore expect the Hamiltonian to be
tridiagonal, with approximately uniform elements \(\eta\) on the first
off-diagonals. As long as the diagonal elements are uniform, they do not make a
difference to the experimental observables so we can treat these as zero without
loss of generality. The expected Hamiltonian is
\begin{equation}
  \mat{H} = \begin{pmatrix}
  0 & \eta & 0 & 0 \\
  \eta & 0 & \eta \\
  0 & \eta & \ddots & \ddots & 0 \\
  0 & & \ddots & 0 & \eta \\
  & & 0 & \eta & 0
  \end{pmatrix}
\end{equation}

For three different wavelengths (774nm, 776nm, 778nm), four columns (indices
8,9,10,11) of the unitary are reconstructed from coherent light and photon pair
interference measurements. This is sufficient to estimate a \(4 \by 4\)
submatrix of the Hamiltonian, by considering equation~\ref{eq:hamiltomo} on an
element-wise basis:
\begin{equation}
  \mat{H}_{ij} = \frac{i}{2 \dt} \left[ \mat{U}_{ik} \of{ t+\dt } \mat{U}_{kj}^{
  \dagger} \of{t} - \mat{U}_{ik} \of{ t-\dt } \mat{U}_{kj}^{\dagger} \of{t}
  \right]
\end{equation}
This demonstrates that any element \(\mat{H}_{ij}\) can be estimated from
measurements of row \(i\) of \(\mat{U} \of{t-\dt}\) and \(\mat{U} \of{t+\dt}\)
and row \(j\) of \(\mat{U} \of{t}\). Noting that for a constant time
Hamiltonian, \(\mat{U} \of{t}\) and \(\mat{U} \of{t^{\prime}}\) commute for any
\(t\) and \(t^{\prime}\), we can reverse the order of the product, and thus the
result also applies for columns. Experimentally, this is significant, since
measuring a row of a unitary requires injecting photons in all input modes and
detecting in one, while measuring a column requires injecting in a single mode
and detecting in all modes. The latter is easier since we generally have
detectors on all output modes.

The quantum walk exhibits some features that aid in the reconstruction process.
Notably, when we apply the real border to the unitary, all elements become real,
regardless of the choice of reference. Deduction of the phases of the unitary
elements reduces to deciding the sign, which only requires us to distinguish
between a dip and an antidip rather than measuring the visibility accurately. We
also benefit from the simplification that ignoring phase information and using
real bordered matrices in equation~\ref{eq:hamiltomo} does not prevent us from
recovering the correct Hamiltonian: the only effect is a factor of \(\pm i\) in
the off diagonal elements.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{figures/hamiltonians.png}
  \caption[Reconstructed Hamiltonians]
  {Hamiltonians reconstructed from the experimental data, for different choices
  of reference row and column in the unitary. Plots are labelled by the (column,
  row) combination used as a reference for signs. The colour scale indicates the
  absolute value of the element, from white (0) to blue (0.4). Tridiagonal
  character is most visible in the \(\left(8,3\right)\) and \(\left(8,4\right)\)
  plots.}
  \label{fig:hamiltonians}
\end{figure}

The results of the experiment are shown in figure~\ref{fig:hamiltonians}.
As noted in section~\ref{sec:SST}, there is a freedom in the unitry
reconstruction where we can make different choices for the reference row and
column for phases. We observe that this choice makes a big difference to the
final results. We show six
different choices of references (column 8 or 9, and row 3, 4 or 6). The
tridiagonal character of the Hamiltonian is most visible for references (8,3)
and (8,4), but does not persist for all choices. This can't be assigned just to
the effect described in section~\ref{sec:SST} where more zeros in the references
result in a worse reconstruction: the choices with the fewest zeros are (9,3)
and (9.4). Instead, I will argue that it is may be due to an inappropriate step
size for the noise present in the experiment.

I determine the time difference by fitting single photon data (since these are
the most reliable) to an existing model of the Hamiltonian \todo{where did Pete
get this?} for a range of times. At each time a distance between the power
distributions (mean Kolmogorov distance) is computed and the minimum distance is
assumed to correspond to the best estimate of the evolution time. The results
are shown in figure~\ref{fig:tevol}, from which we deduce that the effective
evolution times were 6.723, 6.682 and 6.594 for wavelengths 774nm, 776nm and
778nm (respectively).

\begin{figure}
  \centering
  \includegraphics{figures/tevol}
  \caption[Deducing the effective evolution times for different wavelengths]
  {(a) Deducing the effective evolution times for differet wavelengths. The
  error is a mean Kolmogorov distance between the power distributions and has
  minima at 6.723, 6.682 and 6.594 for wavelengths 774nm, 776nm and 778nm
  respectively. The effective (symmetrised) timestep is 0.06. (b) Simulating the
  experimental noise in the amplitude reconstructions, and assessing the optimum
  value of \(\dt\) to use to recover the Hamiltonian. Shaded region represents
  \(\pm 1 \sigma\) variation over Monte-Carlo simulation. The black dotted line
  is the estimated timestep. Error here is a trace distance between the ideal
  and the recovered Hamiltonian. We are not too far from the optimum value, but
  when adding in noise from two-photon data the value shifts dramatically.}
  \label{fig:tevol}
\end{figure}

\begin{figure}
  \centering
  \includegraphics{figures/hamiltoniansim}
  \caption[Simulation of the Hamiltonian tomography under experimental noise]
  {(a) The Hamiltonian describing the quantum walk. (b) Reconstruction of 
  the Hamiltonian by the protocol described in this chapter, under realistic
  experimental conditions. The region in the black box is the submatrix that is
  reconstructed from experimental data. Column 9 and row 4 are used for
  references}
  \label{fig:hamiltoniansim}
\end{figure}

A simulation of the experiment, incorporating some realistic experimental noise
is shown in figure~\ref{fig:hamiltoniansim}. Column 9 and row 4 are used as
references in the simulation and two different noise mechanisms are
taken into account. First, when reconstructing the amplitudes of elements in a
unitary, we inject coherent light into the device and measure the power at each
of the outputs; the error on these measurements is about 1 part in \(10^{4}\).
Second, the signs of the elements (with respect to a reference) are deduced from
2-photon interference dips. In practice, we observe 2-photon count rates for a
range of time delays around zero, and decide whether it is a dip (destructive
interference) or antidip (constructive interference). In the simulation, I look
at the count rate at the centre of the dip (\(Q\)) and far away from the dip
(\(C\)), and add Poissonian noise to both of these values. If \(Q<C\), it is
considered a dip; if \(Q>C\) it is an antidip. The simulation in
figure~\ref{fig:hamiltoniansim} uses a rather optimistic \(10^{8}\) photon pairs
for each observation. This is well above the count rates observed in the lab,
but is deliberately high to take into account the additional information gained
from scanning over values rather than just looking at two points.

The results of the simulation demonstrate that under the experimental
conditions, we would not expect to reliably observe tridiagonal character in the
region (marked with a black square in figure~\ref{fig:hamiltoniansim}). The
general character of the reconstruction is that it is very good in the `left'
half of the device (top left of the figure, modes with low index) but poor in
the `right' half (bottom right of the figure, modes with high index. This
observation is related to the choice of references, and has links to the
clouding phenomenon discussed in chapter~\ref{ch:QCV}. Since we use row 4 as a
reference, count rates for correlations between modes \(i=4\) and \(j \approx
4\) will be much higher than rates for correlations between mode \(i=4\) and \(j
\approx 16\) (the other side of the device). We are therefore able to
reconstruct the signs of the elements much more reliably for these columns of
the unitary, leading to a better estimate of the Hamiltonian.

\section{Alternative methods}
\label{sec:Alternatives}
On inspection of equation~\ref{eq:exponential}, the most straightforward way to
recover the Hamiltonian from a measurement of \(\mat{U}\) would appear to be to
take the logarithm:
\begin{equation}
  \mat{H} = \frac{i}{t} \log \of{\mat{U} \of{t}}
\end{equation}
This can be performed either by diagonalising \(\mat{U}\) or by taking a series
expansion, both of which have their drawbacks. When diagonalising a unitary
matrix, all eigenvalues are unit-modulus complex numbers which permit a freedom
of \(\pm 2 n \pi\) when taking the logarithm. Therefore the resulting
Hamiltonian is not unique. The series expansion can only be used for small
times, requiring the Frobenius norm of \(\identity-\mat{A}\) to be less than
\(1\). More generally, since \(\mat{U} \of{\dt} = \mat{U} \of{t+\dt}
\mat{U}^{\dagger} \of{t}\) for any \(t\), we just require two measurements of
\(\mat{U}\) separated by a small time increment. This requirement is the same as
the time derivative method.

The relative merits of the time derivative compared to the series expansion
depend on the magnitude of this timestep and the amount of noise present in the
measurement of \(\mat{U}\). Simulations for a range of parameters are presented
in figure~\ref{fig:logvsderivative}, and show that for smaller timesteps the
time derivative can outperform the series method in the presence of experimental
noise. For larger timesteps, the series may be a better choice.

\begin{figure}[h]
  \includegraphics{figures/logvsderivative}
  \caption[Comparison of power series and time derivative methods for
  Hamiltonian recovery]
  {Comparison of power series and time derivative as methods for Hamiltonian
  tomography, showing fidelity of the recovered Hamiltonian against the number
  of terms in the power series, for various levels of noise. Shaded regions show
  the fidelity expected from the time derivative method, with the variation
  being from Monte-Carlo simulation with 1000 random evaluations. This method
  does not involve summing terms so is constant. The error bars show the
  expected fidelity using a power series to evaluate the matrix logarithm to the
  expected number of terms. The fidelity flattens off due to noise accumulating
  for higher order terms in the series. The error bar on each point is
  calculated by a Monte-Carlo simulation of 1000 random evaluations.}
  \label{fig:logvsderivative}
\end{figure}

An alternative series-type solution has been described in~\cite{hamiltomo},
where the Hermitian and anti-Hermitian parts of \(\mat{U}\) are considered
separately.

\section{Experimental Details}
\label{sec:HamiltomoExperiment}
Get information from verification paper.

Wavelength shifts were achieved by tuning the laser and tilting the
down-conversion crystal.



