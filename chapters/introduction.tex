\chapter{Introduction}
\label{ch:Introduction}
\section{Quantum Technologies}
\label{sec:Science}
The race for the first quantum computer is on: Academic researchers and private
enterprises \cite{dwave} around the world are pursuing this goal, on a number of
different physical platforms. A large\footnote{Let's say a quantum computer
capable of factoring a 1000 bit number in a day}, error-corrected, universal
quantum computer would represent the pinnacle of the rapidly growing industry
of quantum technologies, and would necessarily change the way we think about
computation, certainly in the domains of security and simulation. Unfortunately,
constructing such a machine is beyond our current capabilities, and is widely
acknowledged as a long-term goal.

Of course, the field of `quantum technologies' is broader than than a
single-minded persual of this goal,
and some technologies are already reaching maturity and
commercial viability. Examples of this are the handful of commercial enterprises
now offering quantum random number generators (qRNG), quantum key distribution
(QKD) systems and quantum metrology tools \cite{idquantique, magiq, qutools}.
These less disruptive technologies have crept out of the lab with little
fanfare, and are likely to continue to grow with industrial rather than
academic backing. In this thesis, I am concerned with a middle ground
between these two sets of technologies: those that have not yet reached maturity
but which may be achieved long before universal quantum computing. I will
mainly discuss aspects of two main types of device falling into this
intermediate category: the Boson Sampler and the analogue simulator. 

A Boson Sampler is a device that is specifically tailored to implement a
single algorithm, \bosonsampling{}. Although the applications of this algorithm
are expected to be rather limited, it is of fundamental interest because it is
believed to be hard for a classical computer to implement. By contrast, a very
simple kind of quantum computer requiring only passive linear optics (plus
single photon sources and detectors) implements it naturally. Relaxing the
requirements on non-linear gates, or measurement and feedforward is an extreme
simplification compared to building a universal linear optical quantum computer,
and it is possible that the first device to truly `beat' a classical computer
will be performing this sampling task.

Analogue simulation lacks the complexity proofs of \bosonsampling{}, but has
much clearer applications. While it is well understood that a universal quantum
computer is capable of efficiently (i.e. with polynomial scaling in the system
size) simulating any other quantum system, a much simpler device could be
capable of simulating a limited subset of other quantum systems. This provides a
potential route to a meaningful quantum simulation without the overheads of
universal quantum computing. In a later chapter, I present experimental results
from just such a simulation: using a passive linear optical circuit to simulate
vibrational states of molecules.

The other results in this thesis are mainly facilitating rather than directly
implementing these intermediate quantum computing models. In any new technology,
a lot of work must go into calibration, control, characterisation and
verification of the devices and these tasks form the bulk of the discussion.
Characterisation of a quantum device cannot be done simply by measuring the
state during operation (a method that works well in the classical world) so
novel tomography procedures need to be developed. Verification is similarly
difficult when discussing algorithms that are not in NP. Neither
\bosonsampling{} nor analogue simulation come with any simple certificate of
correct results so rigorous testing of various aspects of the operation of the
physical devices are particularly important.

Before we get close to universal quantum computing, these intermediate
computational models could have a major impact, and their success or failure
will depend heavily on having adequate characterisation and control procedures
to operate them and be confident in the output. In this thesis, I believe that I
demonstrate such procedures for linear optical quantum computing, paving the way
for scaling up of the physical devices.

\section{Organisation of this Thesis}
\label{sec:Organisation}
In the first chapter, I present some background material which is assumed
knowledge for later chapters. I start with the core concepts of quantum
interference and a brief mathematical description of evolution of quantum
states, which are critical for the section on verification and quantum
simulation, respectively. The other two sections describe the \emph{Reck
scheme}---a universal circuit for linear optics---and the \bosonsampling{}
algorithm---a computational task that is natural in linear optics but is
believed to be beyond the reach of classical computers.

Each of the following four chapters is a presentation of my contribution to a
specific research project, roughly in chronological order of their completion.
Due to the nature of research into photonic quantum technologies, some of these
projects were performed in large collaborations. At the beginning of each
chapter, I have included a statement of the division of work in the project.

Chapter~\ref{ch:DirectDialling} describes a theoretical result concerning the
implementation of random matrices in linear optics and qubits. Although not an
application in itself, Haar random unitaries are important for \bosonsampling{},
and random matrices are important in various other domains.
Chapter~\ref{ch:Simulations} describes a major experimental effort to realise a
kind of analogue quantum simulation in linear optics. Our beliefs about the
quantum advantage in this kind of simulation are firmly rooted in the
complexity results of \bosonsampling{}, but the application to simulation rather
than sampling is much clearer.

In chapter~\ref{ch:QCV}, I address the related tasks of calibration and
verification in quantum technologies, in both experimental and theoretical
contexts. Explicit verification methods (which don't scale well with the size of
the system) are discussed, but the main result is a verification protocol for
linear optics based on observation of quantum interference, which we believe
achieves better scaling. Chapter~\ref{ch:Hamiltomo} presents a tomography
procedure for systems of non-interacting quantum particles. Tomography or
characterisation of devices is closely related to calibration and verification,
and I discuss my procedure in terms of the theory and an experiment in linear
optics.

The final chapter contains some concluding remarks, and my opinions on the
trajectory of the field.
